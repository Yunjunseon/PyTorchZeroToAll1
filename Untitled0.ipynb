{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtJqm95rn+DuF1lVZutlVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yunjunseon/PyTorchZeroToAll1/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r02A_jTrs9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9940341-bc08-408a-a866-bead0e2da60a"
      },
      "source": [
        "# 1. w,MSE 구하기\n",
        "\n",
        "# w를 0부터 100까지 노가다 해보자  선형시스템 가중치 구하기!!!!\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_data = [1.0,2.0,3.0]\n",
        "y_data = [20.0,40.0,60.0]\n",
        "\n",
        "def forward(x):\n",
        "    return w*x  # y_hat   # 가장 기본적인 함수 y=w*x\n",
        "def loss(x,y):\n",
        "  y_pred = forward(x)  # Loss function\n",
        "  return (y_pred - y) **2   # 오차함수  오차제곱을 구함\n",
        "\n",
        "for w in np.arange(0.0,40.0,1.0):\n",
        "  t_sum = 0\n",
        "  for x,y in zip(x_data,y_data):\n",
        "    t_sum += loss(x,y)\n",
        "  t_sum /=3    # t_sum is MSE\n",
        "  print(f'w:{w}, loss:{t_sum}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:0.0, loss:1866.6666666666667\n",
            "w:1.0, loss:1684.6666666666667\n",
            "w:2.0, loss:1512.0\n",
            "w:3.0, loss:1348.6666666666667\n",
            "w:4.0, loss:1194.6666666666667\n",
            "w:5.0, loss:1050.0\n",
            "w:6.0, loss:914.6666666666666\n",
            "w:7.0, loss:788.6666666666666\n",
            "w:8.0, loss:672.0\n",
            "w:9.0, loss:564.6666666666666\n",
            "w:10.0, loss:466.6666666666667\n",
            "w:11.0, loss:378.0\n",
            "w:12.0, loss:298.6666666666667\n",
            "w:13.0, loss:228.66666666666666\n",
            "w:14.0, loss:168.0\n",
            "w:15.0, loss:116.66666666666667\n",
            "w:16.0, loss:74.66666666666667\n",
            "w:17.0, loss:42.0\n",
            "w:18.0, loss:18.666666666666668\n",
            "w:19.0, loss:4.666666666666667\n",
            "w:20.0, loss:0.0\n",
            "w:21.0, loss:4.666666666666667\n",
            "w:22.0, loss:18.666666666666668\n",
            "w:23.0, loss:42.0\n",
            "w:24.0, loss:74.66666666666667\n",
            "w:25.0, loss:116.66666666666667\n",
            "w:26.0, loss:168.0\n",
            "w:27.0, loss:228.66666666666666\n",
            "w:28.0, loss:298.6666666666667\n",
            "w:29.0, loss:378.0\n",
            "w:30.0, loss:466.6666666666667\n",
            "w:31.0, loss:564.6666666666666\n",
            "w:32.0, loss:672.0\n",
            "w:33.0, loss:788.6666666666666\n",
            "w:34.0, loss:914.6666666666666\n",
            "w:35.0, loss:1050.0\n",
            "w:36.0, loss:1194.6666666666667\n",
            "w:37.0, loss:1348.6666666666667\n",
            "w:38.0, loss:1512.0\n",
            "w:39.0, loss:1684.6666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h0SE7xRt3XD",
        "outputId": "fa6b9d5f-bbc8-4420-9898-c8ac55bac255"
      },
      "source": [
        "# Gradient descent algorithm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_data = [1.0,2.0,3.0]\n",
        "y_data = [20.0,40.0,60.0]\n",
        "\n",
        "def forward(x):\n",
        "    return w*x  # y_hat   # 가장 기본적인 함수 y=w*x   y_pred\n",
        "def loss(x,y):\n",
        "  y_pred = forward(x)  # Loss function\n",
        "  return (y_pred - y) **2   # 오차함수  오차제곱을 구함\n",
        "\n",
        "# y' = 26*(w-20)/3\n",
        "def gradient(x,y):\n",
        "  return 2*x*(w*x-y)   \n",
        "\n",
        "# loss = (w*x - y) **2\n",
        "#dloss dw 2*x*(w*x-y)\n",
        "w=0\n",
        "lr = 0.01  \n",
        " # 1 번 \"몇 번\" epoch training\n",
        "for epoch in range(100):\n",
        "   l =0\n",
        "   grad =0\n",
        "   for x,y in zip(x_data,y_data):\n",
        "     grad += gradient(x,y)\n",
        "     grad /3\n",
        "     l += loss(x,y)\n",
        "     w = w-lr*grad\n",
        "     l /=3\n",
        "   print(f'epoch: {epoch}, w : {w}, l:{l}')  \n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Gradient descent algorithm\n",
        "x_data = [1.0,2.0,3.0]\n",
        "y_data = [20.0,40.0,60.0]\n",
        "\n",
        "w = 0  # random value 아무거나 집어넣어!!\n",
        "\n",
        "# forward pass\n",
        "def forward(x,y):\n",
        "  return x*w\n",
        "\n",
        "# Loss function\n",
        "def loss(x,y):\n",
        "  pred_y = forward(x,y)\n",
        "  return (pred_y -y) **2\n",
        "\n",
        "#compute gradient\n",
        "def gradient(x,y):\n",
        "  return 2* x * (w*x-y)\n",
        "\n",
        "# training이란 loss를 줄일 거야\n",
        "# Before training)\n",
        "# traning loop 트레이닝 하는 거 코딩\n",
        "# After training\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, w : 7.50976, l:1118.2148645925927\n",
            "epoch: 1, w : 12.19969523712, l:436.1208367102408\n",
            "epoch: 2, w : 15.128616071924286, l:170.09377198910497\n",
            "epoch: 3, w : 16.95776228030958, l:66.33916298914205\n",
            "epoch: 4, w : 18.100086037200697, l:25.87328445148383\n",
            "epoch: 5, w : 18.81348093126428, l:10.090975196912929\n",
            "epoch: 6, w : 19.25900460334572, l:3.935634094529193\n",
            "epoch: 7, w : 19.53723948284464, l:1.53495726862546\n",
            "epoch: 8, w : 19.71100050391027, l:0.5986567246638307\n",
            "epoch: 9, w : 19.819516346698013, l:0.2334852450362689\n",
            "epoch: 10, w : 19.88728579270907, l:0.09106280344592778\n",
            "epoch: 11, w : 19.929608624976325, l:0.035515880972026105\n",
            "epoch: 12, w : 19.956039741601213, l:0.013851734775199175\n",
            "epoch: 13, w : 19.97254629110686, l:0.005402387637056792\n",
            "epoch: 14, w : 19.982854829351727, l:0.0021070135008126978\n",
            "epoch: 15, w : 19.989292635188104, l:0.0008217673722921559\n",
            "epoch: 16, w : 19.993313122186592, l:0.0003205017974037004\n",
            "epoch: 17, w : 19.995823964562994, l:0.00012500058483988082\n",
            "epoch: 18, w : 19.997392015757164, l:4.875213286450334e-05\n",
            "epoch: 19, w : 19.998371282544536, l:1.901407470917143e-05\n",
            "epoch: 20, w : 19.998982846404452, l:7.41577887580041e-06\n",
            "epoch: 21, w : 19.999364775373735, l:2.8922667642925562e-06\n",
            "epoch: 22, w : 19.999603294598202, l:1.1280281108576e-06\n",
            "epoch: 23, w : 19.999752252716114, l:4.3994815228542844e-07\n",
            "epoch: 24, w : 19.999845278848245, l:1.7158648338312453e-07\n",
            "epoch: 25, w : 19.999903374784076, l:6.692134317783201e-08\n",
            "epoch: 26, w : 19.999939656393153, l:2.610034359620861e-08\n",
            "epoch: 27, w : 19.999962314693402, l:1.0179531722728785e-08\n",
            "epoch: 28, w : 19.999976465073804, l:3.970172489068793e-09\n",
            "epoch: 29, w : 19.999985302156173, l:1.5484277688843891e-09\n",
            "epoch: 30, w : 19.999990821020155, l:6.039104251266368e-10\n",
            "epoch: 31, w : 19.99999426761694, l:2.3553426815317686e-10\n",
            "epoch: 32, w : 19.999996420057993, l:9.186195366299286e-11\n",
            "epoch: 33, w : 19.999997764283258, l:3.582756166428659e-11\n",
            "epoch: 34, w : 19.999998603768066, l:1.3973295013551479e-11\n",
            "epoch: 35, w : 19.999999128036404, l:5.449797977876542e-12\n",
            "epoch: 36, w : 19.999999455448272, l:2.125504240515672e-12\n",
            "epoch: 37, w : 19.99999965992091, l:8.289790371893534e-13\n",
            "epoch: 38, w : 19.999999787616527, l:3.233144642300934e-13\n",
            "epoch: 39, w : 19.99999986736397, l:1.2609756586968902e-13\n",
            "epoch: 40, w : 19.999999917167205, l:4.9179974564747273e-14\n",
            "epoch: 41, w : 19.999999948269924, l:1.9180941928863058e-14\n",
            "epoch: 42, w : 19.999999967693945, l:7.48086050718574e-15\n",
            "epoch: 43, w : 19.99999997982448, l:2.9176495929395707e-15\n",
            "epoch: 44, w : 19.999999987400145, l:1.1379279794622104e-15\n",
            "epoch: 45, w : 19.99999999213124, l:4.4380932094659806e-16\n",
            "epoch: 46, w : 19.999999995085865, l:1.730923914136591e-16\n",
            "epoch: 47, w : 19.999999996931063, l:6.750867416450227e-17\n",
            "epoch: 48, w : 19.999999998083414, l:2.6329356683398563e-17\n",
            "epoch: 49, w : 19.99999999880307, l:1.0268867652775792e-17\n",
            "epoch: 50, w : 19.999999999252502, l:4.0049990850522545e-18\n",
            "epoch: 51, w : 19.99999999953318, l:1.5620101962711815e-18\n",
            "epoch: 52, w : 19.999999999708468, l:6.092003901083711e-19\n",
            "epoch: 53, w : 19.999999999817934, l:2.375926153566614e-19\n",
            "epoch: 54, w : 19.9999999998863, l:9.266407194318505e-20\n",
            "epoch: 55, w : 19.999999999928992, l:3.6140404912991125e-20\n",
            "epoch: 56, w : 19.999999999955655, l:1.409473715377108e-20\n",
            "epoch: 57, w : 19.999999999972307, l:5.4971995436143164e-21\n",
            "epoch: 58, w : 19.999999999982705, l:2.143920113224468e-21\n",
            "epoch: 59, w : 19.9999999999892, l:8.3629498289684075e-22\n",
            "epoch: 60, w : 19.999999999993257, l:3.260668512516664e-22\n",
            "epoch: 61, w : 19.99999999999579, l:1.2711585608072735e-22\n",
            "epoch: 62, w : 19.99999999999737, l:4.948861880555934e-23\n",
            "epoch: 63, w : 19.99999999999836, l:1.9301275506891538e-23\n",
            "epoch: 64, w : 19.999999999998973, l:7.554148857429054e-24\n",
            "epoch: 65, w : 19.999999999999357, l:2.9440770480171053e-24\n",
            "epoch: 66, w : 19.9999999999996, l:1.1443242002158094e-24\n",
            "epoch: 67, w : 19.999999999999748, l:4.537392359623844e-25\n",
            "epoch: 68, w : 19.99999999999984, l:1.7854528447845784e-25\n",
            "epoch: 69, w : 19.9999999999999, l:7.239148634062828e-26\n",
            "epoch: 70, w : 19.99999999999994, l:2.626638017336783e-26\n",
            "epoch: 71, w : 19.99999999999996, l:9.90154834576963e-27\n",
            "epoch: 72, w : 19.999999999999975, l:4.521867577009095e-27\n",
            "epoch: 73, w : 19.999999999999986, l:1.6609320274075583e-27\n",
            "epoch: 74, w : 19.99999999999999, l:7.030795860458677e-28\n",
            "epoch: 75, w : 19.999999999999993, l:3.239588784107622e-28\n",
            "epoch: 76, w : 19.999999999999996, l:1.7576989651146692e-28\n",
            "epoch: 77, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 78, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 79, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 80, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 81, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 82, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 83, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 84, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 85, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 86, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 87, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 88, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 89, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 90, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 91, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 92, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 93, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 94, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 95, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 96, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 97, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 98, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "epoch: 99, w : 19.999999999999996, l:7.339328125611783e-29\n",
            "predict = forward\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsZ2u09NCHCT"
      },
      "source": [
        "# Back-propagation and Autograd\n",
        "import torch\n",
        "\n",
        "x_data = [1.0,2.0,3.0]\n",
        "y_data = [20.0,40.0,60.0]\n",
        "\n",
        "w = torch.tensor([1.0],)   # tensor는 벡터 또는 행렬 값이 아니라 tensor로\n",
        "\n",
        "# forward pass\n",
        "def forward(x,y):\n",
        "  return x*w\n",
        "\n",
        "# Loss function\n",
        "def loss(x,y):\n",
        "  pred_y = forward(x,y)\n",
        "  return (pred_y -y) **2\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNVnqphWt4xY"
      },
      "source": [
        "x ---- Model ---- Y\n",
        "gradient ------------\n",
        "-------------- # loss 그래프  loss w\n",
        "# dloss dw\n",
        "# loss = (w*x -y) **2\n",
        "# dloss dw = 2x(w*x-y)"
      ]
    }
  ]
}